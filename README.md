# Fall 2024: Intro to Text Analysis in Python

**Instructor:** Rebecca Krisel

**Course number:** INAFU6502

**Credits:** 3

**Call number:** 17138

**Email:** [rsk2160@columbia.edu](mailto:rsk2160@columbia.edu)

**Class time:** Wednesdays 9:00 - 10:50am

**Office hours:** On Zoom: Tuesdays 9:00 - 11:00 am or by appointment - schedule [here](https://calendly.com/rsk2160/office-hour) / Wednesdays in-person after class. Please email me in advance. 


---

<br>

## Course Description

We are living in the information age, a historical era characterized by a shift from industrial production to one based on information and computerization. In practical terms, this means we are experiencing a period of history that is overflowing with what is termed "big data." These are text and numeric data sets that are too large or complex to be dealt with by traditional data-processing application software and instead require computational methods like Python for data collection, processing, and analysis. Since "big data" encapsulates all of the digital trails we leave behind in our interconnected world, these data points present new opportunities to uncover insights that are of critical importance to policy leaders today. By using a programming language like Python, we can extract meaning from society's digital imprints to research social questions at a groundbreaking scale. 

In addition to being a powerful tool for working with “big data,” Python can also be used for web development, data analytics, machine learning, data science, data engineering, and artificial intelligence, making Python a highly marketable skill for job seekers. Moreover, since Python mirrors the logic of the English language, its syntax is relatively easy to read and learn for English speakers. Python is also a great programming language for those who want to self-learn since its users form an active and supportive online community dedicated to creating and sharing free tutorials, developing open-source programs, and answering questions. 

This introductory course will explore a variety of approaches to studying text-as-data, collected from newspapers, social media, websites, and any other kind of text data source using the programming language Python. Designed for beginners with no prior coding experience, students will leave this course with beginner-to-intermediate Python programming abilities and the tools to continue building their skills beyond the classroom. Students will learn the fundamentals of the data process in addition to gaining hands-on experience with methods for data collection (e.g., web scraping and working with APIs) and text analysis (e.g., sentiment analysis, topic modeling, and more). Practical in nature, the course will culminate in a final project that will ask students to explore a research question of their choice using the various methods for data collection and analysis learned across the semester, which students can then share as public scholarship and/or with prospective employers. The course content is geared towards students interested in pursuing careers in journalism, marketing, social media strategy, policy analysis, financial analysis, and tech.

**Student who take this course can expect:**

- To gain foundational knowledge of the command line and the Python programming language.
- To practice the principles of data and text analysis, including data wrangling, cleaning, analysis, and visualization.
- To collect text data through web scraping and connecting to APIs with Python.
- To analyze text data using a variety of methodologies including sentimental analysis, topic modeling, named entity recognition, and term-frequency inverse document frequency with Python.
- To use search engines for finding online Python tutorials to troubleshoot coding errors.
- To self-learn Python skills with confidence.
- To communicate with data-science or product teams.

**Who is this course designed for?**

This course is developed for beginners with no prior coding experience. That being said, learning a new programming language can at times be frustrating because you will inadvertently face scripts that will not work with your data without some fine tuning of the code. Students who demonstrate a certain level of patience and ability to seek out online resources to help them troubleshoot when these roadblocks occur will not only succeed in this course, but will be in a better position to continue growing their programming skills with confidence beyond the course. While the instructor is here to provide guidance, a certain level of self-reliance is required in order to not only do well but also enjoy the course material. 

**How to get the most out of this course?** 

For each weekly session, a link to the curriculum is provided in the class schedule. Having a chance to read through the curriculum and test out the code before class allows you to focus on the why and what of the code during the class session. It also gives you the opportunity to troubleshoot any errors in advance and prepare questions for clarification. 

It is also recommended to review the additional readings/resources provided in the class schedule to deepen your understanding of the concepts and to find examples for how these methods are used in practical/research settings. 

**Respecting your peers:** As participants in a beginner's Python course, you will be learning a new skill and language. For some, this may come easily. For others, it may take longer for the material to click. Let's respect each other's differing abilities to grasp this complex new world of programming and help each other out by problem-solving together. 

**Attendance policy:** Your class attendance is mandatory. Failure to properly inform me of a foreseen or unforeseen conflict before class time will result in a diminished participation grade. SIPA no longer offers a Zoom option for class.

**Generative AI Statement:** Generative AI platforms like ChatGPT can be helpful learning tools especially for beginner level coders. For this reason, we will test out how to use these tools in the classroom. That being said, the AI platforms can frequently produce incorrect code scripts. For this reason, it is imperative that you learn how to properly read & write code. Since I cannot control your use of generative AI tools outside of the classroom, all graded work (expect for your final projects) will be done in class. We will also review the proper way to cite when you use AI tools. I will not penalize you for using these tools to help with writing your projects, as long as you are honest about it. 

**Required materials for purchase:** Bringing a laptop computer to class is a requirement. There are no additional materials for purchase required for this course.  
<br>

## Assignments and Grades

**Grading policy:**

As a beginner's coding class geared towards nonprogrammers, the emphasis is not on getting the right answer (though, unfortunately a code will not run with errors), but on the process you bring to bear in attempting to figure out how to work through some of the errors in your code you will undoubtedly face. To that end, across all of your assignments, I encourage you to share the questions you searched for online and the tutorials/resources you utilized on your quest to course-correcting your script. 

**Late policy:** No assignments will be evaluated late. Any late assignment will be given a zero. If you have a personal emergency, or foresee a conflict in advance, please get in touch with me as soon as possible. 

**Assignments:**

Homework:
- Due week 3 (20 points): 
  - Complete [Git & GitHub Fundamentals assignment](https://classroom.github.com/a/-AI4VQwx)

In-class quizzes:
- We will have 5 in-class, hand-written quizzes throughout the semester each worth 20 points. I will drop the lowest grade:
    - Week 4 (testing material from weeks 2 & 3)
    - Week 6 (testing material from weeks 4 & 5)
    - Week 8 (testing material from weeks 6 & 7)
    - Week 10 (testing material from weeks 8 & 9)
    - Week 12 (testing material from week 10 & 11)
   
<br> 
Final research project:
<br> 

For the final research project, you will pair a method of data collection with a method of text analysis to answer a research question of your choice. The final version will be written in Markdown, shared on your GitHub account, will include text (2,000 words), and your code. Some examples of possible topics include: 1) running a sentiment analysis of the comments below a Presidential Address Youtube video; 2) creating a named entity recognition bot to quickly parse out names of companies, people, and events across financial news; or 3) collecting news articles from two publications across the ideological spectrum and using topic modeling to analyze their coverage of the Biden Administration's Inflation Reduction Act. See [here](https://github.com/intro-to-text-analysis-SIPA-S23/final-project) for the complete assignment sheet. 

- Final project deliverables and grade distribution: 
    - Due week 5 (5 points): Schedule a meeting with me to discuss ideas for your final project. You must have a meeting scheduled on the calendar **by 10am before the start of class (the meeting can happen later that week, if needed).**
    - Due week 8 (15 points): Project proposal **due by 10am before the start of class.**
    - Due week 13 (60 points): Final project **due by 10am before the start of class.**
    - Due week 13/14 (20 points): In-class project presentations. 

     <br>


**Grading structure:**

- Class participation 10% (measured based on attendance and participation in class)
- Homework/quiz assignments 40%
- Research project 50%

<br>

## Python Tech Requirements & Installations 

Bringing a laptop computer to class is a requirement for this course. 


## Class Slack Space
To facilitate communication, I created this [Slack space](https://join.slack.com/t/slack-43z4737/shared_invite/zt-21s9xd0b7-UBCV~g5qZzIqlGYg69AD2Q). Follow the link and select "sign in with email" (avoid using the "sign-in with Google" option). Next, enter your email and full name. A verification code will be sent to your email address. Once you receive it, copy/paste it into the Slack page and you should be good to go!  
<br>

I will use our Slack space **during our class time** to share files, links, and other necessary information that you need. In addition, you can use this space **during class time** to send me screenshots of your code/output if you are not able to move forward. I will help you troubleshoot it while projecting your screenshot on the screen so others can learn from the process. You may also post troubleshooting questions in the #general channel outside of class sessions. I will check the Slack channel at least once a day. 

<br>


Slack download: ([macOS](https://slack.com/downloads/mac) / [Windows](https://slack.com/downloads/windows))



---

<br>

## Class Schedule & Curricula

**Week 1 (9/6): Introductions & course overview**

This week, we will review the syllabus and the course objectives. We will also discuss what Python is and how it can be used for text analysis. 

- Topics covered:
    - What is Python?
    - What do we mean by "text-as-data"?
    - What are some practical applications of text analysis in Python?
    - Course structure and objectives
    - Getting the most out of this class
    - Using GitHub & GitHub classroom
    - Final projects

- Requirement in two steps: 
    - Due by Friday  at 11:59pm:
        - [Create a GitHub Account](https://www.wikihow.com/Create-an-Account-on-GitHub)
        - Accept [this dummy assignment](https://classroom.github.com/a/ImDJRwfh) so I can add you to our GitHub organization
    - Due by Sunday at 11:59pm:
        - Follow [these instructions](https://docs.google.com/document/d/1M1xBtDvcX5c5zt1VHJ1Kkv7fA-0aA0m4o3BJq11Bg2o/edit#heading=h.7j3oee9q53i) to accept the invitation to join our GitHub organization (I will send you an invitation on Saturday 1/21)


**Week 2 (9/13): The Command Line + Introduction to Git and Github**

This week, we will learn the command line, which is a way of interacting with your computer without using your mousepad to complete tasks. For example, instead of manually creating a new folder, we will learn how to do that by typing a command. Knowing how to use the command line is an important first step towards learning how to program in Python. 

We will also learn how to use Github, which is an industry-standard tool for collaborative and individual projects. GitHub is a web-based platform for storing and sharing project files online. You will use GitHub throughout the semester to share your homework assignments. Having a GitHub page with evidence of your programming work can serve as a data science portfolio when applying for jobs.


- Topics covered:
    - What is the command line and why is it relevant to Python?
    - Using command prompt (Windows) or terminal (macOS) to perform basic computer commands such as creating a new folder or text file.
    - What is Github? Why is it important for data science?
    - How to use Github for collaboration?
    - How to create a Github repository? 
- Curriculum for this session:
    - Django Girls, ["Introduction to the command-line interface"](https://tutorial.djangogirls.org/en/intro_to_command_line/)
    - Datacamp: [GitHub and Git Tutorial for Beginners](https://www.datacamp.com/tutorial/github-and-git-tutorial-for-beginners)
- Additional readings/resources (not required, but useful!):
    - Tutorials: 
        - Melanie Walsh, _Introduction to Cultural Analytics_, [The Command Line](https://melaniewalsh.github.io/Intro-Cultural-Analytics/01-Command-Line/01-The-Command-Line.html)
        - DHRI: ["Introduction to the Command Line"](https://gc-dri.github.io/Dhrift-GC/workshops/command-line/)
        - The Launch School: [Introduction to the Command Line](https://launchschool.com/books/command_line/read/introduction)
        - DHRI: [Introduction to Git and GitHub](https://curriculum.dhinstitutes.org/workshops/git/)
        - Melanie Walsh, _Introduction to Cultural Analytics_, [Git and GitHub](https://melaniewalsh.github.io/Intro-Cultural-Analytics/04-Data-Collection/04-Git-GitHub.html)
    - Cheat sheets:
        - Tower: [The Command Line Cheat Sheet](https://www.git-tower.com/blog/command-line-cheat-sheet/)
        - Clay Cooper: [Awesome Bash](https://github.com/awesome-lists/awesome-bash)

**Week 3 (9/20): Python Basics**
This week we are diving into Python basics! We will cover foundational concepts for data science in Python and become familiar with [Google Colab](https://colab.research.google.com/?utm_source=scs-index#scrollTo=qL_eyskFWx18), which will be our primary way of interacting with Python. 

- Topics covered:
    - How to interact with Python?
    - Defining variables, functions, lists, loops, comparisons, and conditionals
    - Troubleshooting common errors
- Curriculum for this session:
    - Rebecca Krisel's [_Intro to Python_](https://github.com/rskrisel/intro_to_python_workshop/blob/main/Intro_to_Python.ipynb)
- Assignments (due by 10am on the day of class):
    - Complete [Git & GitHub Fundamentals assignment](https://classroom.github.com/a/6jKjo7hG)
- Additional readings/resources (not required, but useful!):
    - Tutorials: 
        - DHRI [Introduction to Python](https://gc-dri.github.io/Dhrift-GC/workshops/python/) (Introduction - Lists)
        -  Melanie Walsh, _Introduction to Cultural Analytics_, [Python Basics](https://melaniewalsh.github.io/Intro-Cultural-Analytics/02-Python/00-Python.html#)
        -  Datacamp: [Introduction to Python](https://app.datacamp.com/learn/courses/intro-to-python-for-data-science)
     
      

**Week 4 (9/27): Principles of data analysis: Data Manipulation with Pandas**

This week, we will review the principles of data wrangling, cleaning, analysis, and visualization. Wrangling is the process of transforming data from a raw format into one that is legible. Cleaning entails making sure our data does not include inconsistencies such as duplicate entries or information stored in the wrong format. Analysis and visualizations are ways of telling a story with the data, and uncovering insights that may lead to new research questions. 

We will be using the Pandas Pythin library to help us achieve our data processing goals. You can think of a Python library like software that works specifically for Python. Just like you might use Microsoft Excel for data exploration on your personal computer, in Python we have libraries like Pandas that we can download and then import (a fancy word for open) in our Python environment. Pandas, which stands for "Python Data Analysis Library", is specifically designed for data manipulation and analysis. 


- Topics covered:
    - Working with tabular data (a.k.a., spreadsheets)
    - The data process: wrangling, cleaning, analysis, and visualization
    - Pandas basics
- Curriculum for this session:
    - Rebecca Krisel's [Intro to Pandas](https://gist.github.com/rskrisel/407561c530657f275dc728a753c784b0)
- Quiz this week covering materials from weeks 2 & 3
- Additional readings/resources (not required, but useful!):
    - Tutorials:

    - Explainers: 
        - Harvard Business School: [Data Wrangling: What It Is & Why It's Important](https://online.hbs.edu/blog/post/data-wrangling)
        - Stack Abuse: [Guide to Data Visualization in Python with Pandas](https://stackabuse.com/introduction-to-data-visualization-in-python-with-pandas/)
        - Tableau: [Guide To Data Cleaning: Definition, Benefits, Components, And How To Clean Your Data](https://www.tableau.com/learn/articles/what-is-data-cleaning)
        - Towards Data Science: [4 Reasons Why Plotly Is The Best Visualization Library](https://towardsdatascience.com/4-reasons-why-plotly-is-the-best-visualization-library-18c27de05b95#:~:text=Compared%20to%20traditional%20visualization%20tools,your%20data%20before%20plotting%20it.)

**Week 5 (10/4): Principles of text analysis: Cleaning and processing text for analysis with the NLTK library**

This week, we will work with the Natural Language Toolkit (NLTK), a suite of Python libraries for processing and manipulating text-data. We will also review the necessary steps for cleaning and processing our text before we can analyze it by essentially converting each word in a text into an individual data point. 

- Topics covered:
    - Working with text-as-data
    - Cleaning and standardizing text data
    - Preparing texts for computational analysis
    - Basic text analysis tools
    - Using Markdown in Jupyter Notebooks 
- Curriculum for this session:
    - Rebecca Krisel's [Introduction to NLTK](https://github.com/rskrisel/intro_to_nltk/blob/main/Intro_NLTK_workshop.ipynb)
- No quiz this week! 
- Final project deliverable:
    - Schedule a meeting with me [here](https://calendly.com/rsk2160/final-projects?month=2023-10) to discuss ideas for your final research project
- Additional readings/resources (not required, but useful!):
    - Tutorials:
        - Geeks for Geeks: [Generating Word Cloud in Python](https://www.geeksforgeeks.org/generating-word-cloud-python/#:~:text=For%20generating%20word%20cloud%20in,from%20UCI%20Machine%20Learning%20Repository)
    - Explainer:
        - Scribbr: [Textual Analysis | Guide, 3 Approaches & Examples](https://www.scribbr.com/methodology/textual-analysis/)
    - Projects:
        - Digital Humanities at Yale University Library: [Robots Reading Vogue](http://dh.library.yale.edu/projects/vogue/)
        - Boston College Library: [Text and Data Mining Projects](https://libguides.bc.edu/textdatamining/projects)

**Week 6 (10/11): Data collection: Web scraping with the Beautiful Soup library**

This week, we will use the Beautiful Soup Python library for web scraping. Web scraping is the process of extracting content and data from a website using a programming language. In this case, we will web scrape to extract text from websites. 

- Topics covered: 
    - What is web scraping?
    - What are the laws and ethics governing web scraping?
    - How to web scrape?
- Curriculum for this session:
    - Rebecca Krisel's [Web Scraping Media URLs in Python](https://github.com/rskrisel/web_scraping_workshop)
- Quiz this week covering material from weeks 4 & 5 
- Additional readings/resources (not required, but useful!):
    - Tutorials: 
        - Datacamp: [Scraping the Amazon Best Selling Books](https://www.datacamp.com/tutorial/amazon-web-scraping-using-beautifulsoup)
        - Dataquest: [Tutorial: Web Scraping with Python Using Beautiful Soup](https://www.dataquest.io/blog/web-scraping-python-using-beautiful-soup/)
        - Melanie Walsh, _Introduction to Cultural Analytics_, [Web Scraping](https://melaniewalsh.github.io/Intro-Cultural-Analytics/04-Data-Collection/02-Web-Scraping-Part1.html) parts [I](https://melaniewalsh.github.io/Intro-Cultural-Analytics/04-Data-Collection/02-Web-Scraping-Part1.html) & [II](https://melaniewalsh.github.io/Intro-Cultural-Analytics/04-Data-Collection/03-Web-Scraping-Part2.html)
    - Explainers: 
        - AI Multiple: [Watch-outs for Legal and Ethical Web Scraping in 2022](https://research.aimultiple.com/web-scraping-ethics/#:~:text=Scraping%20publicly%20available%20information%20on,personally%20identifiable%20information%20(PII).)

**Week 7 (10/18): Data collection: Working with APIs**

This week, we will learn how to make data requests from an Application Programming Interface (API). APIs allow users to programmatically extract and interact with data under the hood of websites, social networks, applications, and projects. For example, the weather app on your phone connects to the weather bureau's API system, which contains daily weather data, and shows you daily weather updates. We will specifically work with the free version of News API for collecting news data. 

- Topics covered:
    - What is an Application Programming Interface (API)?
    - How is it different from web scraping?
    - How to find APIs?
- Curriculum for this session:
    - Rebecca Krisel's [Intro to APIs with Python](https://gist.github.com/rskrisel/4ff9629df9f9d6bf5a638b8ba6c13a68)
    - Xavier Adam's [An illustrated introduction to APIs](https://medium.com/epfl-extension-school/an-illustrated-introduction-to-apis-10f8000313b9) and [API Whispering 101](https://medium.com/epfl-extension-school/api-whispering-101-e04fbb5a08fd)
- No quiz this week! 
- Final project deliverable:
    - Project proposals due
- Additional readings/resources (not required, but useful!):
    - Tutorials: 
        - Melanie Walsh,_ Introduction to Cultural Analytics_, [Application Programming Interfaces (APIs)](https://melaniewalsh.github.io/Intro-Cultural-Analytics/04-Data-Collection/05-What-Is-API.html)
    - Cheat sheets:
        - Python for Beginners: [List of Python API's](https://www.pythonforbeginners.com/api/list-of-python-apis) 


**Week 8 (10/25): Data collection: Connecting to the YouTube API + connecting to other social media platform**

This week, we will learn how to make data requests from the YouTube API. We will use the Pandas library to wrangle, clean, analyze, and visualize YouTube data. We will also discuss approaches for collecting other types of social media data, including TikTok, Instagram, Facebook, Reddit, and more. 

- Topics covered:
    - How to connect to the YouTube API
    - Ethics of working with Social Media data.
    - How to extract top hashtags.
    - How to get data from Facebook, Instagram, TikTok, Reddit, Spotify, and more. 
-  Curriculum for this session:
    - Rebecca Krisel, [Working with YouTube Data]() TBD
    - Geeks for Geeks's [Python Plotly tutorial]([https://www.kaggle.com/code/kanncaa1/plotly-tutorial-for-beginners/notebook](https://www.geeksforgeeks.org/python-plotly-tutorial/))
- Quiz this week covering material from weeks 6 & 7 
- Additional readings/resources (not required, but useful!):
    - Tutorials:  
        - Collecting data from other social media platforms:
            - American University Library Social Media Research guides: 
                - [Instagram](https://subjectguides.library.american.edu/c.php?g=1238130&p=9060339)
                - [Facebook](https://subjectguides.library.american.edu/c.php?g=1238130&p=9060340)
                - [Youtube](https://subjectguides.library.american.edu/c.php?g=1238130&p=9060343)
                - [TikTok](https://subjectguides.library.american.edu/c.php?g=1238130&p=9060344)
            - Meta's [Crowdtangle](https://www.crowdtangle.com) with [PyCrowdTangle](https://pypi.org/project/PyCrowdTangle/)
            - [Reddit/Pushift API](https://melaniewalsh.github.io/Intro-Cultural-Analytics/04-Data-Collection/14-Reddit-Data.html)
            - [Spotify's API](https://developer.spotify.com/documentation/web-api/libraries/) with [Spotipy](https://spotipy.readthedocs.io/). More details from [Towards Data Science](https://towardsdatascience.com/extracting-song-data-from-the-spotify-api-using-python-b1e79388d50)
            - TikTok: [TikTok hashtag analysis toolset](https://github.com/bellingcat/tiktok-hashtag-analysis) & [PykTok](https://github.com/dfreelon/pyktok)
    - Studies: 
        - Chen, Kaiping, Zening Duan, and Sijia Yang. "Twitter as Research Data: Tools, Costs, Skill Sets, and Lessons Learned." _Politics and the Life Sciences_ 41, no. 1 (ed 2022): 114-30.[ https://doi.org/10.1017/pls.2021.19](https://doi.org/10.1017/pls.2021.19).
            - This is a comprehensive review of the challenges of working with Twitter data, and the pitfalls to avoid. 
        - Chen, Kaiping, and David Tomblin. "Using Data from Reddit, Public Deliberation, and Surveys to Measure Public Opinion about Autonomous Vehicles." _Public Opinion Quarterly_ 85, no. S1 (September 1, 2021): 289-322.[ https://doi.org/10.1093/poq/nfab021](https://doi.org/10.1093/poq/nfab021).
            - This paper explores the difference between public opinions collected from surveys as opposed to social media platforms, focusing on the test case of opinions about autonomous vehicles.
        - Eriksson Krutrök, Moa, and Mathilda Åkerlund. "Through a White Lens: Black Victimhood, Visibility, and Whiteness in the Black Lives Matter Movement on TikTok." _Information, Communication & Society_ 0, no. 0 (April 29, 2022): 1-19.[ https://doi.org/10.1080/1369118X.2022.2065211](https://doi.org/10.1080/1369118X.2022.2065211).
            - This papers studies "how highly visible users in the context of #BlackLivesMatter on TikTok shape the narrative around Black victims of police brutality, the understanding of these narratives by others, and the potential consequences of these portrayals for the movement at large."
        - Proferes, Nicholas, Naiyan Jones, Sarah Gilbert, Casey Fiesler, and Michael Zimmer. "Studying Reddit: A Systematic Overview of Disciplines, Approaches, Methods, and Ethics." _Social Media + Society_ 7, no. 2 (April 1, 2021): 20563051211019004.[ https://doi.org/10.1177/20563051211019004](https://doi.org/10.1177/20563051211019004).
            - This meta study of social science Reddit research looks at the increase in Reddit being used as a data source, the range of disciplines that use Reddit data for research, the ways researchers are getting access to Reddit data, the types of variables researchers are using, the subreddits and topics being studied, the methods of analysis researchers are engaging in, and the emerging ethical questions researching Reddit. 
        - Vydra, Simon, and Jaroslaw Kantorowicz. "Tracing Policy-Relevant Information in Social Media: The Case of Twitter before and during the COVID-19 Crisis." _Statistics, Politics and Policy_ 12, no. 1 (June 1, 2021): 87-127.[ https://doi.org/10.1515/spp-2020-0013](https://doi.org/10.1515/spp-2020-0013).
            - This paper aims to understand how real-time social media data can inform public policy using Twitter data. 
        - Zeng, Jing, and Crystal Abidin. "'#OkBoomer, Time to Meet the Zoomers': Studying the Memefication of Intergenerational Politics on TikTok." _Information, Communication & Society_ 24, no. 16 (December 10, 2021): 2459–81.[ https://doi.org/10.1080/1369118X.2021.1961007](https://doi.org/10.1080/1369118X.2021.1961007).
            - This paper uses #OkBoomer memes on TikTok as a case study to examine the political culture of young people and Gen Z in particular. 

**Week 9 (11/1): Text analysis: Sentiment analysis with YouTube Comment Data**

This week, we will learn how to perform a sentiment analysis using YouTube comment data. Sentiment analysis, also referred to as opinion mining, is a method for identifying the emotional tone behind a body of text. 

- Topics covered: 
    - What is sentiment analysis?
    - What are practical applications of sentiment analysis?
    - How to perform sentiment analysis with YouTube data?
    - How to use this method with other text data sources?
- Curriculum for this session:
    - Rebecca Krisel, [Sentiment Analysis Workshop]TBD
    
- No quiz this week 
- Additional readings/resources (not required, but useful!):
    - Tutorials: 
        - Melanie Walsh, _Introduction to Cultural Analytics_, [Sentiment Analysis](https://melaniewalsh.github.io/Intro-Cultural-Analytics/05-Text-Analysis/04-Sentiment-Analysis.html)
        - Analytics Vidhya: [Performing Sentiment Analysis Using Twitter Data!](https://www.analyticsvidhya.com/blog/2021/07/performing-sentiment-analysis-using-twitter-data/)
        - Learn Data Science: [Sentiment Analysis on Reddit News Headlines with Python's Natural Language Toolkit (NLTK)](https://www.learndatasci.com/tutorials/sentiment-analysis-reddit-headlines-pythons-nltk/)
        - Towards Data Science: [Sentiment Analysis of Social Media with Python](https://towardsdatascience.com/sentiment-analysis-of-social-media-with-python-45268dc8f23f)
    - Studies:
        - Arratia, Argimiro, Gustavo Avalos, Alejandra Cabaña, Ariel Duarte-López, and Martí Renedo-Mirambell. "Sentiment Analysis of Financial News: Mechanics and Statistics. "In _Data Science for Economics and Finance: Methodologies and Applications_, edited by Sergio Consoli, Diego Reforgiato Recupero, and Michaela Saisana, 195-216. Cham: Springer International Publishing, 2021.[ https://doi.org/10.1007/978-3-030-66891-4_9](https://doi.org/10.1007/978-3-030-66891-4_9).
            - This study outlines the basic mechanics for building a forecasting model that uses sentiment indicators derived from textual data.
        - Ceron, Andrea, and Fedra Negri. "Public Policy and Social Media: How Sentiment Analysis Can Support Policy-Makers Across the Policy Cycle." _Rivista Italiana Di Politiche Pubbliche_, no. 3/2015 (2015).[ https://doi.org/10.1483/81600](https://doi.org/10.1483/81600).
            - This study shows how sentiment analysis can be used to study comments of social media users as a way to provide policy makers feedback across the entire policy cycle. 
        - Mohamed Ridhwan, Khairiyah, and Carol Anne Hargreaves. "Leveraging Twitter Data to Understand Public Sentiment for the COVID-19 Outbreak in Singapore." _International Journal of Information Management Data Insights_ 1, no. 2 (November 1, 2021): 100021.[ https://doi.org/10.1016/j.jjimei.2021.100021](https://doi.org/10.1016/j.jjimei.2021.100021).
            - This study uses sentiment analysis to understand the public response to COVID-19 policy measures in Singapore.  
        - Yu, Xiaoyan, Shiyong Wu, Wei Chen, and Mingxi Huang. "Sentiment Analysis of Public Opinions on the Higher Education Expansion Policy in China." _SAGE Open_ 11, no. 3 (July 1, 2021): 21582440211040776.[ https://doi.org/10.1177/21582440211040778](https://doi.org/10.1177/21582440211040778).
            - "This study looks at public opinions on the higher education expansion policy that was specifically implemented by China's government to navigate graduate employment difficulties against the impact of COVID-19."

**Week 10 (11/8): Text analysis: Term Frequency-Inverse Document Frequency (TF-IDF)**

This week, wee will learn about term frequency-inverse document frequency, often abbreviated TF-IDF. TF-IDF is a text analysis method that builds off word frequency but it more specifically tries to identify the most distinctively frequent and significant words.

- Topics covered: 
    - What is TF-IDF?
    - What are practical applications of TF-IDF?
    - How to perform TF-IDF on a collection of speeches?
    - How to use this method with other text data sources?
- Curriculum for this session:
    - Rebecca Krisel, [TF-IDF with Scikit-Learn](https://github.com/rskrisel/tf-idf/blob/main/README.md). Copied from Melanie Walsh's [*Introduction to Cultural Analytics & Python*](https://melaniewalsh.github.io/Intro-Cultural-Analytics/05-Text-Analysis/03-TF-IDF-Scikit-Learn.html). A few code updates were made to reflect the newest versions of Scikit-learn and Pandas. 
- Quiz this week covering material from weeks 8 & 9 
- Additional readings/resources (not required, but useful!):
    - Tutorials:
        - Melanie Walsh, _Introduction to Cultural Analytics_, [TF-IDF Intro](https://melaniewalsh.github.io/Intro-Cultural-Analytics/05-Text-Analysis/01-TF-IDF.html) & [TF-IDF with Scikit-Learn](https://melaniewalsh.github.io/Intro-Cultural-Analytics/05-Text-Analysis/03-TF-IDF-Scikit-Learn.html)
        - Analytics Vidhya:[ Creating a Movie Reviews Classifier Using TF-IDF in Python](https://www.analyticsvidhya.com/blog/2021/09/creating-a-movie-reviews-classifier-using-tf-idf-in-python/)
        - Nick Becker: [Clustering US Laws using TF-IDF and K-Means](https://beckernick.github.io/_posts/2016-08-17-law-clustering/)
        - Programming Historian: [Analyzing Documents with TF-IDF](https://programminghistorian.org/en/lessons/analyzing-documents-with-tfidf)
        - Towards Data Science: [TFIDF Python Example](https://towardsdatascience.com/natural-language-processing-feature-engineering-using-tf-idf-e8b9d00e7e76)
    - Explainer:
        - Capital One: [Understanding TF-IDF for Machine Learning](https://www.capitalone.com/tech/machine-learning/understanding-tf-idf/)
    - Studies: 
        - Mee, Alexander, Elmina Homapour, Francisco Chiclana, and Ofer Engel. "Sentiment Analysis Using TF-IDF Weighting of UK MPs' Tweets on Brexit" _Knowledge-Based Systems_ 228 (September 27, 2021): 107238.[ https://doi.org/10.1016/j.knosys.2021.107238](https://doi.org/10.1016/j.knosys.2021.107238).
            - This study uses TF-IDF and sentiment analysis to study UK MPs' Tweets on Brexit.

**Week 11 (11/15): Text analysis: Named Entity Recognition**

This week, we will learn how to apply Named Entity Recognition (NER) to text files. NER locates and classifies named entities mentioned in unstructured text into preset categories such as person names, organizations, locations, medical codes, time expressions, quantities, monetary values, percentages, and other categories. It's a useful way to quickly parse out the who, what, where, when, how much, etc… in a large body of text. We will use the spaCy Python library to perform NER. 

- Topics covered: 
    - What is Named Entity Recognition (NER)?
    - What are practical applications of NER?
    - How to perform NER with newspaper data?
    - How to use this method with other text data sources?
- Curriculum for this session:
    - Rebecca Krisel, [NER Workshop](https://github.com/rskrisel/NER_workshop)
- No quiz this week 
- Additional readings/resources (not required, but useful!):
    - Tutorials:
        - Melanie Walsh, _Introduction to Cultural Analytics_, [Named Entity Recognition](https://melaniewalsh.github.io/Intro-Cultural-Analytics/05-Text-Analysis/12-Named-Entity-Recognition.html)
        - Brandon Rose: [Entity Extraction and Network Analysis](http://brandonrose.org/ner2sna)
        - Geeks for Geeks: [Named Entity Recognition](https://www.geeksforgeeks.org/named-entity-recognition/)
        - Mattingly, William._ [Introduction to Named Entity Recognition](http://ner.pythonhumanities.com)_, 2021 (2nd ed.).
        - Towards Data Science: [NER for Extracting Stock Mentions on Reddit](https://towardsdatascience.com/ner-for-extracting-stock-mentions-on-reddit-aa604e577be)
    - Explainers:
        - Super.AI: [What is named entity recognition (NER) and how can I use it?](https://medium.com/mysuperai/what-is-named-entity-recognition-ner-and-how-can-i-use-it-2b68cf6f545d)
        - Towards Data Science: [Named Entity Recognition: Applications and Use Cases](https://towardsdatascience.com/named-entity-recognition-applications-and-use-cases-acdbf57d595e)
    - Studies:
        - Fields, Sam, Camille Lyans Cole, Catherine Oei, and Annie T Chen. "Using Named Entity Recognition and Network Analysis to Distinguish Personal Networks from the Social Milieu in Nineteenth-Century Ottoman-Iraqi Personal Diaries." _Digital Scholarship in the Humanities_, August 8, 2022, fqac047.[ https://doi.org/10.1093/llc/fqac047](https://doi.org/10.1093/llc/fqac047).
            - This article employs NER and network analysis to study Joseph Mathia Svoboda's social interactions, as well as his observations of his broader social milieu.
        - Molina-Villegas, Alejandro, Victor Muñiz-Sanchez, Jean Arreola-Trapala, and Filomeno Alcántara. "Geographic Named Entity Recognition and Disambiguation in Mexican News Using Word Embeddings." _Expert Systems with Applications_ 176 (August 15, 2021): 114855.[ https://doi.org/10.1016/j.eswa.2021.114855](https://doi.org/10.1016/j.eswa.2021.114855).
            - This study shows that relationships between geographic and semantic spaces arise when applying word embedding models over a corpus of documents in Mexican Spanish. 
        - Vychegzhanin, Sergey, and Evgeny Kotelnikov. "Comparison of Named Entity Recognition Tools Applied to News Articles." In _2019 Ivannikov Ispras Open Conference (ISPRAS)_, 72-77, 2019.[ https://doi.org/10.1109/ISPRAS47671.2019.00017](https://doi.org/10.1109/ISPRAS47671.2019.00017).
            - A review of different NER tools.

**Week 12 (11/28): Text analysis: Topic Modeling**

This week, we will learn how to use topic modeling to quickly parse out the primary topics across a collection of text files. Topic modeling can help ​​identify clusters of words that show up together in statistically meaningful ways throughout a corpus of text. We will use the Tomotopy Python library for topic modeling. 

- Topics covered: 
    - What is Topic Modeling?
    - What are practical applications of Topic Modeling?
    - How to perform Topic Modeling with newspaper data?
    - How to use this method with other text data sources?
- Curriculum for this session:
    - Rebecca Krisel, [Topic Modeling with Tomotopy](https://github.com/rskrisel/topic_modeling_workshop). Copied from Melanie Walsh's [Topic Modeling with Tomotopy](https://melaniewalsh.github.io/Intro-Cultural-Analytics/05-Text-Analysis/09-Topic-Modeling-Without-Mallet.html), but uses a different dataset.
- Quiz this week covering material from weeks 10 & 11
- Additional readings/resources (not required, but useful!):
    - Explainers:
        - Evans School Policy Analysis & Research Group (EPAR), University of Washington: [Guide to Topic Modeling for Qualitative Research – Building the Model (Part 1)](https://epar.evans.uw.edu/blog/guide-topic-modeling-qualitative-research-building-model-part-1)
        - Scott Weingart: [Topic Modeling for Humanists: A Guided Tour](http://www.scottbot.net/HIAL/index.html@p=19113.html)
    - Tutorials:
        - Melanie Walsh, _Introduction to Cultural Analytics_, [Topic Modeling Overview](https://melaniewalsh.github.io/Intro-Cultural-Analytics/05-Text-Analysis/06-Topic-Modeling-Overview.html) & [Topic Modeling with Tomopy](https://melaniewalsh.github.io/Intro-Cultural-Analytics/05-Text-Analysis/09-Topic-Modeling-Without-Mallet.html)
        - Melanie Walsh, _Introduction to Cultural Analytics_, [Topic Modeling and Reddit](https://melaniewalsh.github.io/Intro-Cultural-Analytics/05-Text-Analysis/10-Topic-Modeling-CSV.html)
        - Melanie Walsh, _Introduction to Cultural Analytics_, [Topic Modeling and Twitter](https://melaniewalsh.github.io/Intro-Cultural-Analytics/05-Text-Analysis/11-Topic-Modeling-Time-Series.html)
        - Programming Historian: [Getting Started with Topic Modeling and MALLET](https://programminghistorian.org/en/lessons/topic-modeling-and-mallet)
    - Projects:
        - Digital Humanities at Yale University Library: [Topic Modeling Vogue](http://dh.library.yale.edu/projects/vogue/topics/20/)
        - Digital Scholarship Lab, Boatwright Library, University of Richmond: [Mining the Dispatch](https://dsl.richmond.edu/dispatch/)
    - Studies:
        - Dahal, Biraj, Sathish A. P. Kumar, and Zhenlong Li. "Topic Modeling and Sentiment Analysis of Global Climate Change Tweets." _Social Network Analysis and Mining_ 9, no. 1 (June 10, 2019): 24.[ https://doi.org/10.1007/s13278-019-0568-8](https://doi.org/10.1007/s13278-019-0568-8).
            - This study reviews a large dataset of geotagged tweets containing certain keywords relating to climate change, analyzed using topic modeling and sentiment analysis.
        - Greene, Derek, and James P. Cross. "Exploring the Political Agenda of the European Parliament Using a Dynamic Topic Modeling Approach." Political Analysis 25, no. 1 (2017): 77-94. [doi:10.1017/pan.2016.7](https://www.cambridge.org/core/journals/political-analysis/article/abs/exploring-the-political-agenda-of-the-european-parliament-using-a-dynamic-topic-modeling-approach/BBC7751778E4542C7C6C69E6BF954E4B)
            - This study analyzes the political agenda of the European Parliament (EP) plenary using topic modeling. 
        - Liu, Qian, Zequan Zheng, Jiabin Zheng, Qiuyi Chen, Guan Liu, Sihan Chen, Bojia Chu, et al. "Health Communication Through News Media During the Early Stage of the COVID-19 Outbreak in China: Digital Topic Modeling Approach." _Journal of Medical Internet Research_ 22, no. 4 (April 28, 2020): e19118.[ https://doi.org/10.2196/19118](https://doi.org/10.2196/19118).
            - Comparing the number of articles for each day and the outbreak development, this study uses topic modeling to show how mass media news reports in China lagged behind the development of COVID-19.
        - Walker, Richard M., Yanto Chandra, Jiasheng Zhang, and Arjen van Witteloostuijn. "Topic Modeling the Research-Practice Gap in Public Administration." _Public Administration Review_ 79, no. 6 (2019): 931-37.[ https://doi.org/10.1111/puar.13095](https://doi.org/10.1111/puar.13095).
            * This study uses topic modeling to highlight which areas of public administration receive more attention than others. 


**Week 13 (12/6)**

- Final project presentations



**Exam Week**
- Final project presentations (Date TBD)
- Final projects due (Date TBD)

---
<br>

## Class Policies

**Academic Integrity:** Throughout this course, you will be searching for and adapting Python scripts that help you accomplish the type of data gathering and analysis you need for your assignments. I do not expect you to write code from scratch. However, pursuant with SIPA's [Code of Academic and Professional Conduct](https://bulletin.columbia.edu/sipa/academic-policies/academic-and-professional-conduct/), it is critical to make note of where you found your code in addition to citing any sources relevant to your assignments. We will review the appropriate format for doing so during our week 3 session. 

The School of International & Public Affairs does not tolerate cheating and/or plagiarism in any form. Those students who violate the Code of Academic & Professional Conduct will be subject to the [Dean's Disciplinary Procedures](http://bulletin.columbia.edu/sipa/academic-policies/discipline-procedures/index.html). Familiarize yourself with the proper methods of citation and attribution. The School provides some useful resources online; we strongly encourage you to familiarize yourself with these various styles before conducting your research.

**Violations of the Code of Academic & Professional Conduct will be immediately reported to the Associate Dean for Student Affairs.**

**SIPA Disability Statement:** SIPA is committed to ensuring that students registered with Columbia University's [Disability Services](https://health.columbia.edu/services/ods) (DS) receive the reasonable accommodations necessary for their full participation in their academic programs. If you are a student with a disability and have a DS-certified accommodation letter, you may wish to make an appointment with the course instructor to discuss your accommodations. Faculty provide disability accommodations to students with DS-certified accommodation letters, and they provide the accommodations specified in such letters.  If you have any additional questions, please contact SIPA’s DS liaison at disability@sipa.columbia.edu and/or 212-854-8690.

